# CIS Advisor Backend (Gemini-Powered Academic Q&A API)

This backend aims to power the chatbot functionality for the **CIS Advisor Chatbot** for the University of Delaware Graduate Computer Science program.
It provides a secure proxy layer for interacting with the Google Gemini API and ensures that no API keys are exposed in the client application.

However, it currently runs a full Express server **on Vercel**, which is functional for a capstone but not the most efficient architecture for Vercelâ€™s serverless runtime model. This README explains both *usage* and *limitations* transparently.

---

## ğŸ¯ Core Goals

* Serve Gemini responses securely (no API keys in client code)
* Fetch structured UD CS program Q&A data
* Constrain model behavior to domain-specific content
* Reject irrelevant queries cleanly
* Output HTML-formatted responses for frontend rendering

---

## ğŸ§  How It Works

### Endpoints

| Endpoint                | Method | Description                                  |
| ----------------------- | ------ | -------------------------------------------- |
| `/api/data-source-json` | GET    | Fetches official UD CS Q&A JSON dataset      |
| `/api/ask-gemini`       | POST   | Sends user query + dataset context to Gemini |
| `/`                     | GET    | Basic server check                           |

### Prompt Strategy

Gemini receives structured instructions to:

* Answer **only** UD Grad CS questions
* Reject unrelated topics
* Format response in HTML (no headers)

This is a prompt-control strategy â€” **not** a substitute for full safety enforcement. For production youâ€™d add intent filters, stricter validation, and possibly a retrieval pipeline.

---

## ğŸ“ Folder Structure

```
CIS-ADVISOR-BACKEND/
â”‚
â”œâ”€â”€ api/                # Vercel serverless dir (currently unused but reserved)
â”‚   â””â”€â”€ node_modules/   # Auto-created dependency folder for Vercel builds
â”‚
â”œâ”€â”€ index.ts            # Main Express server entry point
â”œâ”€â”€ vercel.json         # Vercel deployment configuration
â”œâ”€â”€ tsconfig.json       # TypeScript configuration
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Environment Variables

| Variable         | Required | Description                            |
| ---------------- | -------- | -------------------------------------- |
| `GEMINI_API_KEY` | âœ…        | Google Generative AI API key           |
| `PORT`           | âŒ        | Optional (default: 3000 for local dev) |

`.env` example:

```env
GEMINI_API_KEY=your_key_here
PORT=3000
```

---

## ğŸ—ï¸ Installation & Local Development

```bash
git clone <repo-url>
cd CIS-ADVISOR-BACKEND
npm install
```

Start dev server:

```bash
npm run dev
```

The API runs by default at:

```
http://localhost:3000
```

---

## ğŸ“¡ API Usage

### POST `/api/ask-gemini`

**Request body example:**

```json
{
  "query": "What are the MS CS credit requirements at UD?",
  "jsonData": { /* dataset returned from /api/data-source-json */ }
}
```

**Response example:**

```json
{
"Question": "How do I request an admissions deferment when I cannot attend during my expected enrollment term?",
"Answer": "Submit your admission deferral request to the CIS Graduate Academic Advisor II for review.",
"Category": "Advising"
}
```
---

## ğŸŒ CORS Policy

Current config:

```js
origin: "*"
```

Acceptable for academic deployment.
If public, restrict origins to prevent external sites from hitting your LLM proxy.

---

## ğŸ›¡ï¸ Security Considerations

| Concern              | Current State     | Recommendation                        |
| -------------------- | ----------------- | ------------------------------------- |
| API key safety       | âœ… Backend secured | Good discipline â€” keep it server-side |
| Client-supplied JSON | âœ”ï¸ but unchecked  | Validate structure before injection   |
| Rate limiting        | âŒ                 | Add if going public                   |
| CORS                 | `*`               | Lock down domains for production      |
